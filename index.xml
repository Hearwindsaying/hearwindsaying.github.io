<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lord of Light</title>
    <link>https://hearwindsaying.github.io/</link>
      <atom:link href="https://hearwindsaying.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Lord of Light</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 01 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://hearwindsaying.github.io/images/icon_huc3d79214bb0743bd121a6e63ddf073c8_236102_512x512_fill_lanczos_center_2.png</url>
      <title>Lord of Light</title>
      <link>https://hearwindsaying.github.io/</link>
    </image>
    
    <item>
      <title>Spherical Light Integration over Spherical Caps via Spherical Harmonics</title>
      <link>https://hearwindsaying.github.io/publication/triplesphere/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://hearwindsaying.github.io/publication/triplesphere/</guid>
      <description>&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;p&gt;We present triple sphere, a method to integrate spherical lights over spherical caps via spherical harmonics for rendering applications.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Colvillea</title>
      <link>https://hearwindsaying.github.io/project/example/</link>
      <pubDate>Wed, 15 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://hearwindsaying.github.io/project/example/</guid>
      <description>&lt;!--
# Colvillea
![Dining-room](https://github.com/Hearwindsaying/Colvillea/blob/master/examples/Gallery/dining-room_interactive.jpg)
--&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Colvillea&lt;/strong&gt; is a physically based global illumination renderer running on GPU. It relies on &lt;a href=&#34;https://developer.nvidia.com/optix&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NVIDIA&amp;rsquo;s OptiX&lt;/a&gt; to achieve parallelism by leveraging GPU resources, resulting in high performance ray tracing rendering.&lt;/p&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Here are some motivations and objectives of building Colvillea:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ease for implementation of ray tracer in GPU. Writing a GPU renderer from scratch could be of great difficulty and hard to get optimal performance. Debugging is also a pain in the neck. There might be a way out for all these problems thanks to OptiX.&lt;/li&gt;
&lt;li&gt;Deliver RTX hardware acceleration for faster rendering. OptiX is one of the three ways for enabling RTCores so as to achieve higher ray tracing efficiency when possible.&lt;/li&gt;
&lt;li&gt;Potential for implementation of some state-of-the-art rendering technologies. This is a personal project written during my learning of computer graphics. In the end, it should be both easy and convenient to extend to adding more features. It&amp;rsquo;s also interesting to try out rendering algorithms in GPU to explore a better efficiency.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;h3 id=&#34;light-transport&#34;&gt;Light Transport&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Direct Lighting&lt;/li&gt;
&lt;li&gt;Unidirectional Path Tracing&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;reflection-models&#34;&gt;Reflection Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Lambertian BRDF&lt;/li&gt;
&lt;li&gt;Specular BRDF (Perfect Mirror)&lt;/li&gt;
&lt;li&gt;Specular BSDF (Perfect Glass)&lt;/li&gt;
&lt;li&gt;Ashikhmin-Shirley BRDF (Rough Plastic)&lt;/li&gt;
&lt;li&gt;GGX Microfacet BRDF (Rough Conductor)&lt;/li&gt;
&lt;li&gt;GGX Microfacet BSDF (Rough Dielectric)&lt;/li&gt;
&lt;li&gt;Dielectric-Couductor Two Layered BSDF&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sampler&#34;&gt;Sampler&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Independent Sampler&lt;/li&gt;
&lt;li&gt;Halton QMC Sampler (Fast Random Permutation)&lt;/li&gt;
&lt;li&gt;Sobol QMC Sampler&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;filter-progressive&#34;&gt;Filter (Progressive)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Box filter&lt;/li&gt;
&lt;li&gt;Gaussian filter&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rendering-mode&#34;&gt;Rendering Mode&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Progressive Rendering&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;light-source-models&#34;&gt;Light Source Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Point Light&lt;/li&gt;
&lt;li&gt;Quad Light (Spherical Rectangular Sampling)&lt;/li&gt;
&lt;li&gt;Image-Based Lighting (HDRI Probe)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;camera&#34;&gt;Camera&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Pinhole Camera&lt;/li&gt;
&lt;li&gt;Depth of Field&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;geometry&#34;&gt;Geometry&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Triangle Mesh (Wavefront OBJ)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;miscellaneous&#34;&gt;Miscellaneous&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LDR/HDR Image I/O with Gamma Correction&lt;/li&gt;
&lt;li&gt;Interactive rendering with editing scene&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;work-in-progress&#34;&gt;Work In Progress&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Upgrade to OptiX 7.1&lt;/li&gt;
&lt;li&gt;Refactor the renderer architecture: wavefront ray tracing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;build&#34;&gt;Build&lt;/h2&gt;
&lt;p&gt;Building &lt;strong&gt;Colvillea&lt;/strong&gt; requires OptiX 6.0 (6.5 is preferred) and CUDA 9.0 or above installed. For graphics driver on Windows platform, driver version 436.02 or later is required. All NVIDIA GPUs of Compute Capability 5.0 (Maxwell) or higher are supported but those with Turing architecture is required to access RTX hardware acceleration.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Colvillea&lt;/strong&gt; currently builds on Windows only using &lt;a href=&#34;http://www.cmake.org/download/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CMake&lt;/a&gt; and could be built using MSVC successfully. It&amp;rsquo;s recommeded that create a separte directory in the same level folder as src folder. Note that you are required to use VS2015 or above targeted for 64-bit as CUDA_HOST_COMPILER in configuration step.
For better layout to support interactive rendering, please put imgui.ini file to the same directory as colvillea.vcxproj.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/optix&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nvidia OptiX&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mmp/pbrt-v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PBRT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mitsuba-renderer/mitsuba&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mitsuba&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Living-Room in Unity</title>
      <link>https://hearwindsaying.github.io/project/livingroom-in-unity/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://hearwindsaying.github.io/project/livingroom-in-unity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simple Photo Viewer</title>
      <link>https://hearwindsaying.github.io/project/simple-photo-viewer/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://hearwindsaying.github.io/project/simple-photo-viewer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://hearwindsaying.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://hearwindsaying.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Living-Room in Unity</title>
      <link>https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/</guid>
      <description>&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;
&lt;p&gt;This is my final project for a virtual reality and game development course.
My contribution is bringing a Benedikt Bitterli&amp;rsquo;s famous rendering scene living-room to Unity and showing how we could use various rasterization techniques to approximate the beauty image produced by offline renderer.&lt;/p&gt;
&lt;h2 id=&#34;forewords&#34;&gt;Forewords&lt;/h2&gt;
&lt;p&gt;Ray tracing is an elegant algorithm used in computer graphics to synthesis realistic images.
It shoots tremendous rays to find intersection with geometries in the scene and shading with lights and tries its best to simulate the light transport process in nature.
The algorithm is not so fast however and it is not unusual to spend hours to days rendering a single image for the complex scenes produced by artists in the movie industry.&lt;/p&gt;
&lt;p&gt;Rasterization on the other hand, represents a way to render in an efficient way, which is used ubiquitously in realtime rendering.
Thanks to the efforts of many graphics researchers and engineers for many years, realtime rendering could already produce some good-looking images nowadays.
Consequently, in this project I&amp;rsquo;d like to find out how good it could be in a game engine.&lt;/p&gt;
&lt;p&gt;Note that these days realtime ray tracing becomes popular due to the introduction of NVIDIA&amp;rsquo;s RTX architecture in Turing GPUs, which is able to do the ray intersection in a lightning fast way.
However, it requires a decent graphics card and my old GTX-960M is a bit out-of-date.
So I give up the idea and turn to Unity&amp;rsquo;s HDRP Rendering Pipeline (The High Definition Render Pipeline) for the project.&lt;/p&gt;
&lt;h2 id=&#34;general&#34;&gt;General&lt;/h2&gt;
&lt;p&gt;To generate an image as realistic as possible, we need to choose a GI (Global Illumination) system in Unity.
We will miss the nice indirect lighting, reflections for example if we skip this part.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Global Illumination Off&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Global Illumination On&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@8.1/manual/Images/RayTracedGlobalIllumination1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@8.1/manual/Images/RayTracedGlobalIllumination2.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Unity engine has several built-in solutions for achieving Global Illumination:






  



  
  











&lt;figure id=&#34;figure-two-global-illumination-systems-in-unity-engine-image-courtesy-of-unity-documentation&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/gi_selection_hua26d8df2103457302fbfc682f04efea9_406816_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Two global illumination systems in Unity engine. Image courtesy of Unity documentation.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/gi_selection_hua26d8df2103457302fbfc682f04efea9_406816_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2351&#34; height=&#34;2500&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Two global illumination systems in Unity engine. Image courtesy of Unity documentation.
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;em&gt;Update in 2021: Note that Enlighten is deprecated and we are suggested to use CPU or GPU-based Progressive Lightmapper instead.&lt;/em&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;I attempted to use Enlighten in the first place and do not have a good experience since it is laborious to play with the parameters so as to reach my expectation.
I then turned to CPU and GPU based Progressive Lightmapper for the job.
Progressiveness indicates we could have a somewhat coarse preview immediately and it gradually gets refined as we wait.
This is usually preferred by lots of artists since it saves time for fast iterations.&lt;/p&gt;
&lt;h2 id=&#34;sky-and-fog-volume&#34;&gt;Sky and Fog Volume&lt;/h2&gt;
&lt;p&gt;To begin with, we should have a sky!&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-our-sunset-skybox-for-the-living-room&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/preview-sky_hubdd691bfcb56470ac77983f49f64118c_107420_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Our sunset skybox for the living room.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/preview-sky_hubdd691bfcb56470ac77983f49f64118c_107420_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;816&#34; height=&#34;412&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Our sunset skybox for the living room.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;I chose to use a sky from HDRI probe, which would also be the primary luminary for our scene.
We just need to import our HDRI panorama as a cubemap by setting the &lt;em&gt;Texture Shape&lt;/em&gt; as &lt;em&gt;Cube&lt;/em&gt; and using &lt;em&gt;Trilinear Filter&lt;/em&gt;:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-import-our-skybox-with-cubemap-and-trilinear-filter&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/sky_hu99c0f549956912e1c05f729b784d2551_98905_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Import our skybox with cubemap and trilinear filter.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/sky_hu99c0f549956912e1c05f729b784d2551_98905_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;526&#34; height=&#34;913&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Import our skybox with cubemap and trilinear filter.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We could preview our loaded HDRI Sky in the scene as well by setting up the Volume:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-set-up-the-hdri-sky-in-volume&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/k1-volume_hu5d239a4fff77850319bec18e785299c2_41828_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Set up the HDRI Sky in Volume.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/k1-volume_hu5d239a4fff77850319bec18e785299c2_41828_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;524&#34; height=&#34;603&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Set up the HDRI Sky in Volume.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Remember we need to specifiy the sky in the &lt;strong&gt;Lighting/Environment HDR&lt;/strong&gt;.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-specify-our-sky-in-lighting&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/k0-hdri_hu7abc091b94530d9ed6cc69867db6611e_14655_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Specify our sky in Lighting.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/k0-hdri_hu7abc091b94530d9ed6cc69867db6611e_14655_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;526&#34; height=&#34;147&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Specify our sky in Lighting.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;cleanup-the-scene&#34;&gt;Cleanup the Scene&lt;/h2&gt;
&lt;p&gt;The living-room scene is from &lt;a href=&#34;https://benedikt-bitterli.me/resources/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Benedikt Bitterli&amp;rsquo;s Rendering Resources&lt;/a&gt;:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-the-living-room-i-chosed&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s1_about_the_scene_hu350185b3c38b62c15b8396f0ca354de7_234245_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;The living room I chosed.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s1_about_the_scene_hu350185b3c38b62c15b8396f0ca354de7_234245_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;357&#34; height=&#34;377&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    The living room I chosed.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;I first import all meshes (*.obj) into Maya and group the objects by materials according to the provided scene description file (.xml).
This could reduce our time for authoring and assigning materials in Unity later.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-group-and-name-objects-by-materials-in-maya&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s2-maya-group_hu8259d58428a0ed5c619003201f809572_54871_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Group and name objects by materials in Maya.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s2-maya-group_hu8259d58428a0ed5c619003201f809572_54871_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;406&#34; height=&#34;659&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Group and name objects by materials in Maya.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;I also check the normals facing outwards and ensure the Y axis is up (the convention Unity uses):&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-visualize-the-normal-to-check-the-face-orientation&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s3-fix-normals_huc6ab547b876d684fbdc5574d665b69bd_116357_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Visualize the normal to check the face orientation.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s3-fix-normals_huc6ab547b876d684fbdc5574d665b69bd_116357_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1028&#34; height=&#34;433&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Visualize the normal to check the face orientation.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;import-the-scene&#34;&gt;Import the Scene&lt;/h2&gt;
&lt;p&gt;After fixing all issues in the &lt;a href=&#34;#cleanup-the-scene&#34;&gt;last section&lt;/a&gt;, it should work well to export the scene as FBX and import in Unity.&lt;/p&gt;
&lt;p&gt;However, there is an issue to be considered &amp;ndash; what is our scale of the scene?
This is important since we have limited precision for representing decimal in computer science.
For example, the intersection point may slightly below the surface and when it shoots a shadow ray to the light to find out whether it&amp;rsquo;s blocked or not, it will be occluded by itself &amp;ndash; a phenomena known as &lt;em&gt;shadow acne&lt;/em&gt;.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-shadow-acne-artifacts-due-to-the-error-of-loating-point-image-courtesy-of-scratchpixel-20&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/shadow-acne_huae33be763e457e02e9f30c734dc3c82b_67078_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Shadow acne artifacts due to the error of loating point. Image courtesy of Scratchpixel 2.0.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/shadow-acne_huae33be763e457e02e9f30c734dc3c82b_67078_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;495&#34; height=&#34;300&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Shadow acne artifacts due to the error of loating point. Image courtesy of Scratchpixel 2.0.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;An idea is to offset the intersection pooint by epsilon, which should be related to the scale of the scene.
If our scene lives in a small world, &amp;lsquo;a miss (ray epsilon in this context) is as good as a mile&amp;rsquo;!
Our scale or units thus should chosed in a &lt;em&gt;consistent&lt;/em&gt; way throughout the scene to avoid these annoying artifacts.&lt;/p&gt;
&lt;p&gt;One of the simplest solutions is to compare the imported scene with the default primitive in Unity.
A standard cube here has the length of 1 meter and I just scale our scene to make it match the scale &amp;ndash; a 5m*10m*5m living room.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-scale-our-scene-according-to-the-standard-cube-in-unity-to-fix-the-unit&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s4-fix-units_huf77f1ccd5971731f43d7a94b0eb08397_313746_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Scale our scene according to the standard cube in Unity to fix the unit.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s4-fix-units_huf77f1ccd5971731f43d7a94b0eb08397_313746_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1141&#34; height=&#34;913&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Scale our scene according to the standard cube in Unity to fix the unit.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;testing-global-illumination&#34;&gt;Testing Global Illumination&lt;/h2&gt;
&lt;p&gt;After importing the models, it is time for playing around with the global illumination system now!
We could first ignore the minute props in the scene such as plants and the statue and check whether the global illumination works well for the &amp;lsquo;global&amp;rsquo; environment, the look of the house.
So enable the paneling, ceiling, floor, wall and the fireplace glass only and tick &lt;strong&gt;Contribute Global Illumination&lt;/strong&gt; under &lt;strong&gt;Inspector/Mesh Renderer/Lighting&lt;/strong&gt;.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-parameters-required-to-contribute-global-illumination&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s5-test-gi_hu85dcdafa156fa4c3540bb47e9082aa0b_60566_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Parameters required to contribute global illumination.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s5-test-gi_hu85dcdafa156fa4c3540bb47e9082aa0b_60566_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;722&#34; height=&#34;424&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Parameters required to contribute global illumination.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;And we could enable the baked GI solution under &lt;strong&gt;Lighting/Mixed Lighting&lt;/strong&gt; and &lt;strong&gt;Lighting/Lightmapping Settings&lt;/strong&gt;.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-settings-for-lightmap-baking&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s7-bake-settings_hub785a82e1ae4847f984efaa34704e828_64608_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Settings for lightmap baking.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s7-bake-settings_hub785a82e1ae4847f984efaa34704e828_64608_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;488&#34; height=&#34;839&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Settings for lightmap baking.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Progressive GPU lightmapper is preferred when we have enough GPU memory (at least 4GB), which is generally the way much faster than the CPU one.
It requires us to have a GPU supporting OpenCL 2.2 as well.&lt;/p&gt;
&lt;p&gt;Multiple importance sampling should always be enabled since it helps reduce variance by combining several sampling strategies.
Throwing more direct and indirect samples helps reduce noises even more, but it increases the baking time as well.
So we have to make a trade-off between the quality and time.
But that&amp;rsquo;s not the whole story, since we could apply filtering even if we use fewer number of samples to get a decent result.
By selecting the &lt;strong&gt;Auto&lt;/strong&gt; setting for the &lt;strong&gt;Filtering&lt;/strong&gt;, unity will do all the magic for us!&lt;/p&gt;
&lt;p&gt;Since we are using baked GI solution, so we must have a second UV for lightmapping.
This is done by Unity by enabling &lt;strong&gt;Generate Lightmap UVs&lt;/strong&gt; during FBX import.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-let-unity-generate-the-lightmap-uvs-for-us&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s6-bake-lightmap_hu1b611a90266552ce4aaf65ee5ff737aa_28564_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Let Unity generate the lightmap UVs for us.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s6-bake-lightmap_hu1b611a90266552ce4aaf65ee5ff737aa_28564_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;472&#34; height=&#34;347&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Let Unity generate the lightmap UVs for us.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;material-and-reflections&#34;&gt;Material and Reflections&lt;/h2&gt;
&lt;p&gt;Since we have already grouped the meshes by materials, we could just assign each group of mesh with a unique material.
For the ceiling and the wall, we want a Lambertian BSDF as specified in the xml file.
I just use a simple &lt;strong&gt;HDRP/Lit&lt;/strong&gt; shader with &lt;strong&gt;Metallic = 0&lt;/strong&gt; and &lt;strong&gt;Smoothness = 0&lt;/strong&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Material&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Base Color&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;ceiling&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R=G=B=0.578596&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;wall&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R=G=B=0.4528&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;






  



  
  











&lt;figure id=&#34;figure-setup-for-our-ceiling-material-to-match-a-lambertian-bsdf&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s8-ceiling_hue3e5938cd77d6a0f4b9b36a4f19f5511_47924_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Setup for our ceiling material to match a Lambertian BSDF.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s8-ceiling_hue3e5938cd77d6a0f4b9b36a4f19f5511_47924_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;487&#34; height=&#34;744&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Setup for our ceiling material to match a Lambertian BSDF.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;For the floor and paneling, we need to emulate the substrate BSDF or rough-coating BSDF with the underlying BSDF being Lambertian and coated with a rough dielectric BSDF with GGX distribution.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-illustration-for-light-transport-in-a-rough-coating-bsdf-image-courtesy-of-mitsuba-05-documentation&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/bsdf-roughcoating_hu3f79080cbf3f02342fde08edac28fffc_24073_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Illustration for light transport in a rough-coating BSDF. Image courtesy of Mitsuba 0.5 documentation.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/bsdf-roughcoating_hu3f79080cbf3f02342fde08edac28fffc_24073_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;276&#34; height=&#34;182&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Illustration for light transport in a rough-coating BSDF. Image courtesy of Mitsuba 0.5 documentation.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Thanks to the Laurent Belcour&amp;rsquo;s excellent work on &lt;a href=&#34;https://belcour.github.io/blog/research/publication/2018/05/05/brdf-realtime-layered.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;layered material&lt;/a&gt;, we could easily simulate this kind of coating material in Unity using &lt;strong&gt;StackLit&lt;/strong&gt; shader.&lt;/p&gt;
&lt;p&gt;We shall use the Shader Graph to finish the task.
Here is what we have for the floor:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-shader-graph-setup-for-the-layered-floor-material&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s9-floor_hu1a47d37f5f18a40c9d8363819b464c8d_166244_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Shader Graph setup for the layered floor material.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s9-floor_hu1a47d37f5f18a40c9d8363819b464c8d_166244_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1029&#34; height=&#34;597&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Shader Graph setup for the layered floor material.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;And the paneling material:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-shader-graph-setup-for-the-paneling&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s10-paneling_hud6a9fa9d9b3b7164ee5b05ac03baeee1_122837_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Shader Graph setup for the paneling.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s10-paneling_hud6a9fa9d9b3b7164ee5b05ac03baeee1_122837_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1028&#34; height=&#34;656&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Shader Graph setup for the paneling.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The last material for our &amp;ldquo;global&amp;rdquo; environment is the fireplace, which is a perfectly smooth specular shader.
Besides setting the &lt;strong&gt;Smoothness = 1&lt;/strong&gt; with &lt;strong&gt;StackLit&lt;/strong&gt;, we need to deal with the reflection.
This is one of the nasty stuff in realtime rendering &amp;ndash; though reflection itself is a part of the global illumination, we still need to explicitly achieve the effect by using another technique &amp;ndash; Reflection Probes.
Here we create a reflection probe to capture the interior environment for the fireplace.
Clicking &lt;strong&gt;Bake&lt;/strong&gt; option under the &lt;strong&gt;Lighting&lt;/strong&gt;, we get the nice reflection for the fireplace!&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-fix-the-reflection-of-our-fireplace&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s11-probe_huf7311762a8657f1581716e2d2d8655e4_642384_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Fix the reflection of our fireplace.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s11-probe_huf7311762a8657f1581716e2d2d8655e4_642384_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;497&#34; height=&#34;884&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Fix the reflection of our fireplace.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;But not for the interior, oops!&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-a-weird-look-of-our-interior&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s12-probe-global_hu10a572bf403dc60ccca727cb6df375f0_89498_2000x2000_fit_q75_lanczos.jpg&#34; data-caption=&#34;A weird look of our interior.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s12-probe-global_hu10a572bf403dc60ccca727cb6df375f0_89498_2000x2000_fit_q75_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1025&#34; height=&#34;819&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    A weird look of our interior.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;It may not be so obvious, but the interior gets reflection from the exterior HDRI or Skybox instead of the interior &amp;ndash; the floor is not missing, but reflecting the bright sky!
This is due to the lack of another reflection probe for the scene.&lt;/p&gt;
&lt;p&gt;So we could easily address this by adding another probe:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-use-yet-another-reflection-probe-for-interior-reflections&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s13-probe_hu2cd6589240396ec2e70578358766f6a4_351086_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Use yet another reflection probe for interior reflections.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s13-probe_hu2cd6589240396ec2e70578358766f6a4_351086_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;838&#34; height=&#34;739&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Use yet another reflection probe for interior reflections.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;and bake!&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-a-corrected-interior-look&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s14-fixed-probe_hu2e1beffb6dc2d6aef9eba3883c524c79_1796049_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;A corrected interior look.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s14-fixed-probe_hu2e1beffb6dc2d6aef9eba3883c524c79_1796049_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1147&#34; height=&#34;915&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    A corrected interior look.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;details-and-props&#34;&gt;Details and Props&lt;/h2&gt;
&lt;p&gt;It looks we are on the right track now, we could start to add more details for the scene!&lt;/p&gt;
&lt;p&gt;After enabling all props meshes, we begin with the brushed steel.
It is like the fireplace glass, but we set the &lt;strong&gt;Metallic = 1&lt;/strong&gt; to simulate the metal.
As for the painting back and the table wood, we could use the same material with the floor, with different base color textures.
The sofa, painting, pot, leaves and dirt are just the Lambertians so &lt;strong&gt;HDRP/Lit&lt;/strong&gt; works well.&lt;/p&gt;
&lt;p&gt;Note that we need to use &lt;strong&gt;Translucent&lt;/strong&gt; material type for the leaves and alpha cutout the geometries according to the leaves map.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-material-setup-for-the-leaves&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s15-leaves_hu9fa8ead7ed8f99c0081f098db4326a0f_48926_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Material setup for the leaves.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s15-leaves_hu9fa8ead7ed8f99c0081f098db4326a0f_48926_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;486&#34; height=&#34;677&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Material setup for the leaves.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Finally, we use a transparent surface type for the glass material.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-material-setup-for-the-glass&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s16-glass_huf41281ace084686322704a8f74c9be37_38573_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Material setup for the glass.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s16-glass_huf41281ace084686322704a8f74c9be37_38573_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;486&#34; height=&#34;557&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Material setup for the glass.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Here comes another nasty stuff in realtime rendering &amp;ndash; refraction.
Refraction is notoriously difficult to achieve in realtime rendering and is usually approximated by Screen Space Refraction:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-enable-screen-space-refraction-in-the-volume-setting&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s18-glass_hu42099c2298054070666b371df6c103e4_37353_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Enable Screen Space Refraction in the volume setting.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s18-glass_hu42099c2298054070666b371df6c103e4_37353_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;487&#34; height=&#34;500&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Enable Screen Space Refraction in the volume setting.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;results-and-discussions&#34;&gt;Results and Discussions&lt;/h2&gt;
&lt;p&gt;After adding up all props and setting up the materials correctly, we could simply bake our GI and here is what I get:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-final-baked-result-for-the-living-room-in-unity&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s19-final_hu63d3b0438845b5173e3df9478da16846_1250146_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Final baked result for the living room in Unity!&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s19-final_hu63d3b0438845b5173e3df9478da16846_1250146_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1025&#34; height=&#34;814&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Final baked result for the living room in Unity!
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;It looks kind of cool &amp;ndash; perhaps not in a sense of realism but in a artistic style.&lt;/p&gt;


















&lt;figure id=&#34;figure-path-traced-reference-image-rendered-by-my-colvilleahttpshearwindsayinggithubioprojectexample-renderer&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../../project/example/featured.jpg&#34; data-caption=&#34;Path traced reference image rendered by my &amp;lt;strong&amp;gt;&amp;lt;a href=&amp;#34;https://hearwindsaying.github.io/project/example/&amp;#34;&amp;gt;Colvillea&amp;lt;/a&amp;gt;&amp;lt;/strong&amp;gt; renderer.&#34;&gt;


  &lt;img src=&#34;../../project/example/featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Path traced reference image rendered by my &lt;strong&gt;&lt;a href=&#34;https://hearwindsaying.github.io/project/example/&#34;&gt;Colvillea&lt;/a&gt;&lt;/strong&gt; renderer.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;By comparing with the ground truth image from the ray tracing [sGT Image], we find that the glass seems to be weird and we lack all the nice occlusion from the objects.
As for the user&amp;rsquo;s experience, I think it requires artists to pay more attention to the stuff behind rendering.
For example, we have to consider the resolution or padding for the lightmap UVs, tuning the baking parameters, fixing light leaking due to the lack of reflection probes etc.&lt;/p&gt;
&lt;p&gt;However, the image generated still looks good and the performance in realtime framerates (~80 FPS) is appealing; or we have to wait for hours to get a noise-free image using offline ray tracing!&lt;/p&gt;
&lt;p&gt;Here is another result by leveraging the post-processing pipeline:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-featured-image-for-the-living-room-after-post-processing&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s20-post-process_hu12b3998c6f435296f99393114ce4c24f_1826204_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Featured image for the living-room after post processing.&#34;&gt;


  &lt;img data-src=&#34;https://hearwindsaying.github.io/post/render-the-livingroom-in-unity/s20-post-process_hu12b3998c6f435296f99393114ce4c24f_1826204_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1137&#34; height=&#34;912&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Featured image for the living-room after post processing.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.unity3d.com/2018/09/24/the-high-definition-render-pipeline-getting-started-guide-for-artists/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unity&amp;rsquo;s Blog for HDRP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@7.1/manual/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unity&amp;rsquo;s Documentation for HDRP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=k05G2QNrvPE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ArchViz with Unity&amp;rsquo;s HDRP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Unity-Technologies/FontainebleauDemo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fontainebleau Demo &amp;ndash; A Unity&amp;rsquo;s Official Demo for HDRP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3197517.3201289&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Laurent Belcour&amp;rsquo;s Layered BSDF Paper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
